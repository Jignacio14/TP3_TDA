\section{Construyendo aproximaciones}

\subsection{Solución Greedy}

Como es sabido el Hitting Set Problem pertenece a NP-completo y por lo tanto no existe ninguna solución que de en tiempo polinomial de una respuesta exacta en todo caso posible, pero, es posible construir una aproximación a la solución utilizando una estrategia greedy

\subsubsection{La estrategia}

Para construir una aproximación greedy se deben cumplir las siguientes reglas:

\begin{itemize}
    \item Aplicar una regla sencilla \\
    \item Debe conseguir un óptimo local al problema actual \\
    \item Se deben repetir estas reglas hasta conseguir una respuesta \\
\end{itemize}

Por lo tanto se construye la siguiente estrategia greedy para resolver el problema:

\begin{itemize}
    \item Conseguir el jugador más representativos cuya frecuencia de aparición es la más alta entre todos los jugadores \\
    \item Eliminar todos los subconjuntos en donde este jugador aparezca \\
    \item Repetir hasta que no quede ningún subconjunto de jugadores \\
\end{itemize}

\subsubsection{La implementación}

Siguiendo los pasos anteriormente mencionados se construye la implementación en python del algoritmo de aproximación greedy 

\begin{lstlisting}[language=Python, caption= aproximación greedy, label=python_code]
def aprox_hs_by_greedy(subsets: set, a: set):
    aprox_sol = set()
    missing_sets = set(range(len(subsets)))
    subsets = list(subsets)
    return _aprox_greedy(subsets, aprox_sol, missing_sets)

def _aprox_greedy(subsets: list, aprox_sol: set, missing_sets: set):
    while(not is_solution(aprox_sol, subsets)):
        diference = set()
        player = find_most_frequent_player(missing_sets, subsets)
        for i in missing_sets: 
            if has_a_player(subsets[i], player):
                diference.add(i)
        aprox_sol.add(player)
        missing_sets.difference_update(diference)
    return aprox_sol

def find_most_frequent_player(missing_sets: set, subsets: list):
    frequency = dict()
    for subset_index in missing_sets:
        for player in subsets[subset_index]:
            frequency[player] = frequency.get(player, 0) + 1
    most_frequent_player = max(frequency, key=frequency.get)
    return most_frequent_player
\end{lstlisting}

\subsubsection{Complejidad temporal}

Para analizar la complejidad temporal del algoritmo vemos que se hacen las siguientes iteraciones sobre el algoritmo: 

\begin{enumerate}
    \item Se busca al jugador más frecuente, esto es recorre $m$ subconjuntos y por cada uno de ellos sus $k$ jugadores\\
    \item Se ejecuta un ciclo while, que en el peor de los casos realiza $m$ iteraciones y en cada una de esas realiza la llamada a buscar el jugador más frecuente
\end{enumerate}

Por lo tanto se puede concluir que el algoritmo tiene la siguiente complejidad:

$$
    T(n) = O(m^2 \cdot k)
$$
Donde $k$ se puede estimar como el cardinal del mayor subconjunto perteneciente a $m$ y $m$ como el cardinal de $m$. Importante destacar que esta cota corresponde al peor caso posible y el algoritmo podría comportarse mejor de lo esperado dependiendo de la cantidad de jugadores que necesite $k$

\subsection{Solución por programación lineal}

Para construir esta aproximación se relajan las reglas implementadas en el caso de programación lineal entera y se permite que los valores de los jugadores varíen entre 0 y 1. Por lo que las ecuaciones en este caso serían:
\begin{align}
  \sum_{b_j \in B_i} b_j &\geq 1 \quad \forall B_i \in B \\
  \sum_{b_j \in B_i} b_j &\geq 1 \quad \forall B_i \in B \\
  b_j &\in [0,1] 
\end{align}
\subsubsection{Complejidad temporal de la aproximación}
Debido a que se esta aproximación se realiza aplicando programación lineal, es claro que, para resolver las ecuaciones planteadas se utiliza el algoritmo Simplex, el cual, se encuentra acotado como:
\begin{align}
    T(n) = O(n^9)
\end{align}
Si bien es cierto que se pueden dar determinadas condiciones para que la complejidad temporal de la resolución aproximada sea menor a la anteriormente mencionada, no se puede descartar que algoritmo Simplex que es el motor de la solución posee la cota superior dicha 
\subsubsection{Clasificación de la aproximación}
Definamos $M$ como el subconjunto con la cantidad máxima de jugadores y definamos $|M| = b$ si se desean relajar las ecuaciones y establecer que dentro de las respuesta vayan solo los elementos cuya respuesta en la solución es: $1/b$. En el peor de los casos para todos los elementos de ese subconjunto todos los valores en la ecuación pueden tomar $1/b$, aunque también, eso quiere decir que todos los valores estarían incluidos. Como $1/b$ es un valor pequeño en comparación a los posibles valores que puedan tomar los otros jugadores dentro de sus ecuaciones, recordar que la suma de jugadores por cada subconjunto debe valer al menos uno, para otros conjuntos es probable también se incluyan otros valores que no son necesarios en la respuesta óptima. Por lo tanto, volviendo a $|M|$, se observa que como mucho necesita un representante, es cierto que, pueden existir dentro de $M$ la presencia de otros jugadores esenciales en la respuesta óptima pero en un principio en el peor caso se incluyen $b - 1$ jugadores no esenciales, entonces, esto es una $b - 1$ aproximación
\subsubsection{Una muestra de r(A)}

A continuación se toma una muestra aleatoria de los $r(A)$ de la solución
\begin{table}[H]
    \centering
    \begin{tabular}{cc}
    \hline
    \textbf{m} & \textbf{r(a)} \\
    \hline
    104 & 1.875000 \\
    15 & 1.000000 \\
    152 & 1.181818 \\
    196 & 1.700000 \\
    150 & 1.300000 \\
    16 & 1.000000 \\
    161 & 1.000000 \\
    66 & 1.000000 \\
    27 & 1.400000 \\
    95 & 1.000000 \\
    115 & 2.142857 \\
    153 & 1.076923 \\
    92 & 2.125000 \\
    112 & 1.900000 \\
    35 & 1.000000 \\
    135 & 1.000000 \\
    45 & 3.000000 \\
    96 & 2.000000 \\
    19 & 3.000000 \\
    163 & 1.600000 \\
    \hline
    \end{tabular}
    \caption{Descripción de la tabla.}
    \label{tabla:resultados}
\end{table}

\subsection{Medición de las aproximaciones}
\begin{figure}[H]
    \begin{minipage}{0.5\textwidth}
        \centering
        \includegraphics[width=\linewidth]{graficos/greed.png}
        \caption{Aproximación greedy}
        \label{fig:imagen1}
    \end{minipage}%
    \begin{minipage}{0.5\textwidth}
        \centering
        \includegraphics[width=\linewidth]{graficos/continous.png}
        \caption{Aproximación por prog. lineal}
        \label{fig:imagen2}
    \end{minipage}
\end{figure}

En las gráficas anteriores se puede observar la duración en microsegundos para el mismo set de datos utilizado a la hora de tomar mediciones sobre las soluciones exactas al problema. Se observa que la solución greedy posee una variabilidad mayor entre valores de $m$, a comparación de la solución por programación lineal que se mantiene mas estable entre los diferentes tamaños de $m$

\subsection{Comparación entre los tamaños de los óptimos}

En el siguiente gráfico se podrán observar los valores de los óptimos resultantes de ambas aproximaciones y el óptimo arrojado por una de las soluciones exactas, es fácilmente apreciable que, la aproximación por un algoritmo greedy es la cual posee el menor error a la hora de aproximar. Al mismo tiempo, se aprecia que la aproximación realizada por programación lineal no se perfila como una buena aproximación a utilizar 

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{graficos/optimos.png}
\end{figure}

En este gráfico se analizan las distancias con el óptimo real de ambas aproximaciones, confirmando una vez más que la aproximación por el algoritmo greedy tiende a distar menos del óptimo real, siendo la máxima distancia al óptimo de 5 elementos 

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{graficos/distanciaaloptimo.png}
\end{figure}

\subsection{Mediciones en volumen de las aproximaciones}
\begin{figure}[H]
    \begin{minipage}{0.5\textwidth}
        \centering
        \includegraphics[width=\linewidth]{graficos/greedvol.png}
        \caption{Tiempo en vol. por greedy}
        \label{fig:imagen1}
    \end{minipage}%
    \begin{minipage}{0.5\textwidth}
        \centering
        \includegraphics[width=\linewidth]{graficos/plvol.png}
        \caption{Tiempo en vol. por prog. Lineal}
        \label{fig:imagen2}
    \end{minipage}
\end{figure}
\section{Conclusión}

En conclusión se analizo en profundidad un análisis y diversas resoluciones del problema de conjunto de impacto, construyendo tanto estrategias que permitían obtener una solución exacta como aproximaciones diversas aproximaciones que varían en comportamiento y complejidad temporal es importante destacar lo siguiente:

\begin{itemize}
    \item La aproximación por programación lineal tuvo menor variabilidad entre los tiempos de ejecución que la solución aproximada por una estrategia greedy a pesar de tener una complejidad temporal menor\\
    \item La aproximación greedy genera óptimos más cercanos a los reales para cualquier valor tamaño del conjunto de subconjuntos siendo pues que para los datos utilizados para resolver todos los algoritmos implementados la mayor distancia al óptimo fue 6 \\
    \item La solución por programación lineal entera encuentra con los mejores tiempos entre todos los algoritmos la respuesta \\ 
\end{itemize}